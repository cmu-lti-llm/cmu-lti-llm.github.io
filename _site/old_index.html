<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>CMU-LTI-LLM</title>
    <!-- Adding Bulma CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.3/css/bulma.min.css">
    <!-- Adding custom styles -->
    <style>
        body {
            padding: 2rem;
        }
    </style>
</head>
<body>
<ul>
    <li><a href="#studying-data-contamination">Studying Data Contamination</a></li>
    <li><a href="#studying-multilingual-capabilities">Studying Multilingual Capabilities</a></li>
    <li><a href="#fine-tuning-vs-prompting">Fine-tuning v/s Prompting</a></li>
    <li><a href="#transfer-capabilities">Transfer Capabilities</a></li>
    <li><a href="#hardware-and-compute-optimizations">Hardware and Compute Optimizations</a></li>
    <li><a href="#generalization">Generalization</a></li>
    <li><a href="#evaluation-metrics">Evaluation Metrics</a></li>
    <li><a href="#distribution-shifts">Distribution Shifts</a></li>
    <li><a href="#llms-as-tools-for-scientific-discovery">LLMs as Tools for Scientific Discovery</a></li>
    <li><a href="#self-reflection-in-llms">Self-Reflection in LLMs</a></li>
    <li><a href="#lets-write-a-paper-using-gpt">Let's Write a Paper Using GPT*</a></li>
    <li><a href="#lets-build-an-open-source-natdev">Let's Build an Open-Source Nat.dev</a></li>
    <li><a href="#hallucination-in-llms">Hallucination in LLMs</a></li>
    <li><a href="#llms-as-creative-tools">LLMs as Creative Tools</a></li>
    <li><a href="#trickle-down-economics-for-language-models">"Trickle Down Economics" for Language Models?</a></li>
    <li><a href="#personalization-human-feedback-rlhf-chain-of-hindsight-etc">Personalization, Human Feedback (RLHF),
        Chain of Hindsight etc.</a></li>
    <li><a href="#gpt-for-cs-education">GPT for CS Education</a></li>
    <li><a href="#inversed-chatgpt-llms-asking-for-help">Inversed ChatGPT (LLMs Asking for Help)</a></li>
    <li><a href="#meta-prompting">Meta Prompting</a></li>
</ul>
<section id="studying-data-contamination">
    <h2>Studying Data Contamination</h2>
    <p>Jesse Dodge has APIs for 6 datasets that have been used to pre-train LLMs. We can use these APIs to study the
        effects of data contamination on the pre-training process. We will need access to the dataset APIs as well as
        benchmark datasets for comparison.</p>
    <p>Resources Needed: Dataset APIs; benchmark datasets</p>
    <p>Votes: skhanuja, Ankit, atharvak, anubhak</p>
</section>
</body>
</html>
