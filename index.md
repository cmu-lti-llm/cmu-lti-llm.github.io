---
title: CMU LTI Seminar on Large Language Models!
feature_image: "../images/neon-light-ring.jpeg"
feature_text: <h2 class="whitetext highlighted">We are serious, it is all about LLMs</h2>
---

<div class="container">
  <p>
    Carnegie Mellon University's Language Technologies Institute (CMU LTI) is excited to host a seminar exploring the world
    of Large Language Models (LLMs). Join us as we dive into the research, development, applications, ethics, and societal
    implications of these models.
  </p>

  <p>
    We welcome attendees to engage with renowned experts, participate in thought-provoking discussions, and learn about the
    future of LLMs in academia, industry, and beyond. We will also host a hackathon for groups to explore and build an
    LLM-related idea.
  </p>

  <div class="links">
    <a class="button" href="https://lijuncheng16.wixsite.com/my-site">Event Page</a>
    <a class="button" href="{{ site.baseurl }}/talks" style="background: #f68140">Talk Recordings</a>
    <a class="button" href="https://lijuncheng16.wixsite.com/my-site/gallery" style="background: #0d94e7">Gallery</a>
  </div>
</div>

<div class="schedule-container">
  <details>
    <summary>
      <h2 class="schedule-title">ğŸ“… Schedule</h2>
    </summary>

    <h3>Day 1: Saturday (4/1/2023)</h3>
    <ul>
      <li>9:00 - 9:30 AM: ğŸ« Registration and Welcome ğŸ¤—</li>
      <li>9:30 - 10:45 AM: ğŸ¤ Short Talks (Industry & Academia Experts)</li>
        <ul>
          <li>9:30 - 9:45 AM: Graham Neubig ğŸ“</li>
          <li>9:50 - 10:05 AM: Hoda Heidari ğŸ“</li>
          <li>10:10 - 10:25 AM: Susan Zhang ğŸ“</li>
          <li>10:30 - 10:45 AM: Niket Tandon ğŸ“</li>
        </ul>
      <li>10:45 - 11:00 AM: â˜• Coffee Break</li>
      <li>11:00 - 11:30 AM: ğŸ’¡ What can you do with LLMs? Hackathon Introduction, Group Formation</li>
      <li>11:30 AM - 12:30 PM: ğŸ½ï¸ Lunch Break</li>
      <li>12:30 - 3:00 PM: ğŸ Hackathon - Day 1</li>
        <ul>
          <li>Hackathon Begins! ğŸ‰</li>
          <li>Short Tutorials on prompting ğŸ“š</li>
        </ul>
      <li>3:00 - 4:00 PM: ğŸ™ï¸ Panel Discussion: The Future of Large Language Models</li>
        <ul>
          <li>Melvin Johnson, Abhishek Nagaraj, Yoav Artzi, Niket Tandon, and Susan Zhang</li>
          <li>Host: Emma Strubell</li>
        </ul>
      <li>4:00 - 4:30 PM: â˜• Coffee Break</li>
      <li>4:30 - 6:00 PM: ğŸ Hackathon - Day 1 (Continuation)</li>
    </ul>

    <h3>Day 2: Sunday (4/2/2023)</h3>
    <ul>
      <li>9:00 AM - 1:00 PM: ğŸ Hackathon - Day 2 (Continuation)</li>
      <li>1:00 - 2:00 PM: ğŸ½ï¸ Lunch Break (with Hackathon Groups)</li>
      <li>2:45 - 4:30 PM: ğŸ Hackathon continues</li>
      <li>4:30 - 5:30 PM: ğŸ¤ Presentations</li>
      <li>5:30 - 6:00 PM: ğŸ‰ Closing remarks and prizes ğŸ†</li>
    </ul>

  </details>
</div>
<div class="speaker-container">
  <details>
  <summary><h2>ğŸ“ Speakers & Panelists</h2></summary>

  <ul>
    <li>Susan Zhang: Research Scientist @ Meta AI</li>
    <li>Yoav Artzi: Associate Professor @ Cornell Tech</li>
    <li>Hoda Heidari: Assistant Professor @ CMU MLD</li>
    <li>Abhishek Nagaraj: Assistant Professor @ Berkeley Haas</li>
    <li>Niket Tandon: Sr. Research Scientist @ AI2</li>
    <li>Melvin Johnson: Researcher @ Google</li>
    <li>Graham Neubig: Associate Professor @ CMU LTI</li>
    <li>Emma Strubell: Assistant Professor @ CMU LTI</li>
  </ul>
  </details>
</div>

<div class="venue-container">

  <details>
  <summary><h2>ğŸ¢ Venue</h2></summary>

  <ul>
    <li>Rashid Auditorum (GHC 4401)</li>
    <li>Rashid Auditorium is located on the fourth floor of the Gates-Hillman Center. The easiest way to access this room is
    via the Forbes Avenue entrance to GHC.</li>
    <li><a href="https://lti.cs.cmu.edu/phd/sites/default/files/GHC%20Maps.pdf">Building Map</a></li>
    <li>ğŸ“ Full Address: 5000 Forbes Ave, Pittsburgh, PA 15213</li>
  </ul>
  </details>
</div>
<div class="sponsor-container">
  <summary><h2>ğŸ’° Sponsors</h2></summary>

<div class="logo">
    <a href="https://inspiredco.ai/" target="_blank" rel="noopener"><img alt="Inspire" class="stripe-logo" src="https://static.wixstatic.com/media/a451d8_3a729eeabea14ea3b13122c8120ee405~mv2.png/v1/fill/w_358,h_93,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/a451d8_3a729eeabea14ea3b13122c8120ee405~mv2.png"></a>
    <a href="https://www.lti.cs.cmu.edu/"><img alt="LTI" src="https://static.wixstatic.com/media/a451d8_86f6d33140cd4823802175a2744238a2~mv2.png/v1/fill/w_391,h_108,al_c,lg_1,q_85,enc_auto/a451d8_86f6d33140cd4823802175a2744238a2~mv2.png"></a>
    <a href="https://www.duolingo.com/"><img alt="Duolingo" src="https://static.wixstatic.com/media/a451d8_8abf296831704962866e7f2889f6d1e8~mv2.png/v1/fill/w_157,h_157,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/a451d8_8abf296831704962866e7f2889f6d1e8~mv2.png"></a>
</div>
<div class="logo">
    <a href="https://www.svclnk.com/"><img alt="ServiceLink" src="https://static.wixstatic.com/media/62e256_72e7e3961280440c998d710edbd19b25~mv2.png/v1/fill/w_327,h_75,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/logo.png"></a>
    <a href="https://www.3m.com/3M/en_US/health-information-systems-us/create-time-to-care/clinician-solutions/transcription-solutions/fluency-for-transcription/"><img alt="MModal" src="https://static.wixstatic.com/media/62e256_93d5f192fbbe4153aaeb8409a9dfe969~mv2.jpeg/v1/crop/x_139,y_271,w_2191,h_519/fill/w_346,h_82,al_c,q_80,usm_0.66_1.00_0.01,enc_auto/3M_MModal_horiz_rectangle.jpeg"></a>
    <a href="https://www.amazon.science/tag/alexa"><img alt="Alexa" src="https://static.wixstatic.com/media/62e256_8a0b874b86bb4c058dd74851d7cde94d~mv2.png/v1/fill/w_219,h_66,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/Amazon_Logo_RGB_SQUID.png"></a>
</div>
</div>
### Hackathon ideas::

##### Studying data contamination

##### Studying multilingual capabilities

##### Fine-tuning vs. Prompting

##### Transfer Capabilities

##### Hardware and Compute Optimization

##### Generalization

##### Evaluation Metrics

##### Distribution shifts

##### LLMs as Tools for Scientific Discovery

##### Self-reflection in LLMs

##### Let's write a paper with GPT!

##### Let's build an open source Nat.dev

##### Hallucination in LLMs

##### LLMs as Creative Tools

##### Trickle-down Economics for Language Models

##### Personalization with Human Feedback

##### GPT for CS Education 
##### Inversed ChatGPT
##### Meta-prompting 
